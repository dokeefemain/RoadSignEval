{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dokee\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lib.utils import non_max_suppression, intersection_over_union, load_checkpoint, cells_to_bboxes\n",
    "from lib.utils import intersection_over_union as iou\n",
    "#from lib.YOLOV3 import YOLOv3 as YOLO\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from lib import config as C\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, ImageFile, ImageDraw, ImageFont\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from lib.utils import (\n",
    "    cells_to_bboxes,\n",
    "    iou_width_height as iou,\n",
    "    non_max_suppression as nms,\n",
    "    plot_image\n",
    ")\n",
    "from matplotlib import pyplot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "config_yolo = [\n",
    "    (32, 3, 1),\n",
    "    (64, 3, 2),\n",
    "    [\"B\", 1],\n",
    "    (128, 3, 2),\n",
    "    [\"B\", 2],\n",
    "    (256, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (512, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (1024, 3, 2),\n",
    "    [\"B\", 4],  # To this point is Darknet-53\n",
    "    (512, 1, 1),\n",
    "    (1024, 3, 1),\n",
    "    \"S\",\n",
    "    (256, 1, 1),\n",
    "    \"U\",\n",
    "    (256, 1, 1),\n",
    "    (512, 3, 1),\n",
    "    \"S\",\n",
    "    (128, 1, 1),\n",
    "    \"U\",\n",
    "    (128, 1, 1),\n",
    "    (256, 3, 1),\n",
    "    \"S\",\n",
    "]\n",
    "\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bn_act=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias= not bn_act, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.leaky = nn.LeakyReLU(0.1)\n",
    "        self.use_bn_act = bn_act\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_bn_act:\n",
    "            return self.leaky(self.bn(self.conv(x)))\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, use_residual=True, num_repeats=1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for repeat in range(num_repeats):\n",
    "            self.layers += [\n",
    "                nn.Sequential(\n",
    "                    CNNBlock(channels, channels // 2, kernel_size=1),\n",
    "                    CNNBlock(channels // 2, channels, kernel_size=3, padding=1),\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        self.use_residual = use_residual\n",
    "        self.num_repeats = num_repeats\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            if self.use_residual:\n",
    "                x = x + layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ScalePrediction(nn.Module):\n",
    "    # False\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pred = nn.Sequential(\n",
    "            CNNBlock(in_channels, 2 * in_channels, kernel_size=3, padding=1),\n",
    "            CNNBlock(\n",
    "                2 * in_channels, (num_classes + 5) * 3, bn_act=False, kernel_size=1\n",
    "            ),\n",
    "        )\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (\n",
    "            self.pred(x)\n",
    "            .reshape(x.shape[0], 3, self.num_classes + 5, x.shape[2], x.shape[3])\n",
    "            .permute(0, 1, 3, 4, 2)\n",
    "        )\n",
    "\n",
    "\n",
    "class YOLOv3(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=80):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.layers = self._create_conv_layers()\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []  # for each scale\n",
    "        route_connections = []\n",
    "        test = 0\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ScalePrediction):\n",
    "                outputs.append(layer(x))\n",
    "                continue\n",
    "\n",
    "            x = layer(x)\n",
    "            print(x.size())\n",
    "            if test >= 0:\n",
    "                test += 1\n",
    "                tmp = x.to(\"cpu\").numpy()\n",
    "                ix = 1\n",
    "                #pyplot.rcParams.update({'figure.max_open_warning': 0})\n",
    "                pyplot.figure(figsize=(40,20))\n",
    "                for _ in range(4):\n",
    "                    for _ in range(8):\n",
    "                        ax = pyplot.subplot(4,8, ix)\n",
    "                        ax.set_xticks([])\n",
    "                        ax.set_yticks([])\n",
    "                        #ax.set_aspect\n",
    "\n",
    "                        pyplot.imshow(tmp[0,ix-1,:,:], cmap=\"gray\")\n",
    "                        ix += 1\n",
    "                #pyplot.show()\n",
    "                pyplot.savefig(\"lib/datasets/test_images/test/layer_\"+str(test)+\".png\")\n",
    "                pyplot.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if isinstance(layer, ResidualBlock) and layer.num_repeats == 8:\n",
    "                route_connections.append(x)\n",
    "\n",
    "            elif isinstance(layer, nn.Upsample):\n",
    "                x = torch.cat([x, route_connections[-1]], dim=1)\n",
    "                route_connections.pop()\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def _create_conv_layers(self):\n",
    "        layers = nn.ModuleList()\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for module in config_yolo:\n",
    "            if isinstance(module, tuple):\n",
    "                out_channels, kernel_size, stride = module\n",
    "                layers.append(\n",
    "                    CNNBlock(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding=1 if kernel_size == 3 else 0,\n",
    "                    )\n",
    "                )\n",
    "                in_channels = out_channels\n",
    "\n",
    "            elif isinstance(module, list):\n",
    "                num_repeats = module[1]\n",
    "                layers.append(ResidualBlock(in_channels, num_repeats=num_repeats,))\n",
    "\n",
    "            elif isinstance(module, str):\n",
    "                if module == \"S\":\n",
    "                    layers += [\n",
    "                        ResidualBlock(in_channels, use_residual=False, num_repeats=1),\n",
    "                        CNNBlock(in_channels, in_channels // 2, kernel_size=1),\n",
    "                        ScalePrediction(in_channels // 2, num_classes=self.num_classes),\n",
    "                    ]\n",
    "                    in_channels = in_channels // 2\n",
    "\n",
    "                elif module == \"U\":\n",
    "                    layers.append(nn.Upsample(scale_factor=2),)\n",
    "                    in_channels = in_channels * 3\n",
    "\n",
    "        return layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_eval_boxes(x, model, anchors, iou_threshold, threshold, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    x = x.to(device)\n",
    "    tmp = torch.reshape(x,(1,x.size()[0],x.size()[1],x.size()[2]))\n",
    "    all_pred_boxes = []\n",
    "    train_idx = 0\n",
    "    with torch.no_grad():\n",
    "        preditcions = model(tmp)\n",
    "    batch_size = tmp.shape[0]\n",
    "    bboxes = bboxes = [[] for _ in range(batch_size)]\n",
    "    for i in range(3):\n",
    "        S = preditcions[i].shape[2]\n",
    "        anchor = torch.tensor([*anchors[i]]).to(device) * S\n",
    "        boxes_scale_i = cells_to_bboxes(\n",
    "            preditcions[i], anchor, S = S, is_preds=True\n",
    "\n",
    "        )\n",
    "        for idx, (box) in enumerate(boxes_scale_i):\n",
    "            bboxes[idx] += box\n",
    "\n",
    "    for idx in range(batch_size):\n",
    "        nms_boxes = non_max_suppression(\n",
    "            bboxes[idx],\n",
    "            iou_threshold = iou_threshold,\n",
    "            threshold = threshold,\n",
    "            box_format = \"midpoint\"\n",
    "        )\n",
    "\n",
    "        for nms_box in nms_boxes:\n",
    "            all_pred_boxes.append([train_idx] + nms_box)\n",
    "            train_idx += 1\n",
    "    model.train()\n",
    "    return all_pred_boxes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "test_transforms = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=C.IMAGE_SIZE),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=int(C.IMAGE_SIZE),\n",
    "            min_width=int(C.IMAGE_SIZE),\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "        ),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255, ),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    ")\n",
    "path = \"lib/datasets/LISA/LISA/\"\n",
    "S=[C.IMAGE_SIZE // 32, C.IMAGE_SIZE // 16, C.IMAGE_SIZE // 8]\n",
    "anchors = C.ANCHORS\n",
    "check = \"lib/models/checkpoint_test.pth.tar\"\n",
    "model = YOLOv3(num_classes=C.NUM_CLASSES).to(C.DEVICE)\n",
    "optimizer = optim.Adam(\n",
    "        model.parameters(), lr=C.LEARNING_RATE, weight_decay=C.WEIGHT_DECAY\n",
    "    )\n",
    "load_checkpoint(\n",
    "        check, model, optimizer, C.LEARNING_RATE\n",
    "    )\n",
    "ids = pd.read_csv(\"lib/datasets/ids.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 416, 416])\n",
      "torch.Size([1, 64, 208, 208])\n",
      "torch.Size([1, 64, 208, 208])\n",
      "torch.Size([1, 128, 104, 104])\n",
      "torch.Size([1, 128, 104, 104])\n",
      "torch.Size([1, 256, 52, 52])\n",
      "torch.Size([1, 256, 52, 52])\n",
      "torch.Size([1, 512, 26, 26])\n",
      "torch.Size([1, 512, 26, 26])\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "torch.Size([1, 512, 13, 13])\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "torch.Size([1, 1024, 13, 13])\n",
      "torch.Size([1, 512, 13, 13])\n",
      "torch.Size([1, 256, 13, 13])\n",
      "torch.Size([1, 256, 26, 26])\n",
      "torch.Size([1, 256, 26, 26])\n",
      "torch.Size([1, 512, 26, 26])\n",
      "torch.Size([1, 512, 26, 26])\n",
      "torch.Size([1, 256, 26, 26])\n",
      "torch.Size([1, 128, 26, 26])\n",
      "torch.Size([1, 128, 52, 52])\n",
      "torch.Size([1, 128, 52, 52])\n",
      "torch.Size([1, 256, 52, 52])\n",
      "torch.Size([1, 256, 52, 52])\n",
      "torch.Size([1, 128, 52, 52])\n"
     ]
    }
   ],
   "source": [
    "test_image = \"lib/datasets/test_images/stop_test.jpg\"\n",
    "image = np.array(Image.open(test_image).convert(\"RGB\"))\n",
    "augmentations = test_transforms(image=image)\n",
    "image1 = augmentations[\"image\"]\n",
    "bboxes = get_eval_boxes(image1, model, C.ANCHORS, iou_threshold = C.NMS_IOU_THRESH, threshold=C.CONF_THRESHOLD)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}